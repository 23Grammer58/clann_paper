%  LaTeX support: latex@mdpi.com 
%  For support, please attach all files needed for compiling as well as the log file, and specify your operating system, LaTeX version, and LaTeX editor.

%=================================================================
\documentclass[journal,article,submit,pdftex,moreauthors]{Definitions/mdpi} 

% MDPI counters
\firstpage{1} 
\makeatletter \setcounter{page}{\@firstpage} \makeatother
\pubvolume{1}
\issuenum{1}
\articlenumber{0}
\pubyear{2025}
\copyrightyear{2025}
\datereceived{ } \daterevised{ } \dateaccepted{ } \datepublished{ } 
\hreflink{https://doi.org/}

% Custom macros
\newcommand{\vect}[1]{\boldsymbol{#1}}
\newcommand{\tr}{\operatorname{tr}}

% TikZ for architecture/pipeline figures
\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning,fit}

% Title and metadata
\Title{Convex Neural Network based on Laplace Stretch for Data-Driven Hyperelasticity}
\TitleCitation{CLaNN (Convex Laplace Neural Network)}

\newcommand{\orcidauthorA}{0000-0002-5860-4419}
\newcommand{\orcidauthorD}{0000-0001-8324-6695}
\newcommand{\orcidauthorC}{0000-0002-9936-8379}
\newcommand{\orcidauthorB}{0000-0002-4050-214X}
\Author{Dits D. $^{1, *}$\orcidA{}, Salamatova V.$^{2}$ \orcidD{}, Liogky A.$^{3}$\orcidC{} , Ovsepyan A.$^{1, 2}$\orcidB{}}
\AuthorNames{Dits D., et al.}
\isAPAStyle{\AuthorCitation{Dits D., et al.}}{\isChicagoStyle{\AuthorCitation{Dits D., et al.}}{\AuthorCitation{Dits D., et al.}}}
\address{$^{1}$ \quad Scientific Center for Information Technology and Artificial Intelligence, Sirius University of Science and Technology, 1 Olympiyskii pr., Sochi 354340, Russia; daniil.dits@gmail.com; 

$^{2}$ \quad Sechenov University, Moscow 119991, Russia

$^{3}$ \quad Marchuk Institute of Numerical Mathematics of the Russian Academy of Sciences, Moscow 119333, Russia}
% \address{$^{2}$ \quad Sechenov University, Moscow 119991, Russia}
% \address{$^{3}$ \quad Marchuk Institute of Numerical Mathematics of the Russian Academy of Sciences, Moscow 119333, Russia}
% \address{$^{4}$ \quad Sechenov University, Moscow 119991, Russia; Sirius University, Sochi 354340, Russia}
\corres{Correspondence: Author to whom correspondence should be addressed}

\abstract{%
Background: Accurate data-driven hyperelastic models must satisfy mechanical constraints while achieving competitive runtimes for large-deformation simulations.%
Methods: We introduce CLaNN, an input-convex neural network formulated in the Laplace stretch measure.
The architecture is trained using synthetic biaxial tests on a Maltese-cross membrane generated with a Neo-Hookean reference model. 
Results: We tested CLaNN for interpolating and extrapolating stresses with a small data size. 
For membrane-inflation benchmarks—both homogeneous and heterogeneous thickness—CLaNN predicts $\mathbb{S}$ stresses that closely match the Neo-Hookean reference, achieving under 5\% relative $L^2$ error with sufficient training data. 
The network's strict convexity allows Newton-type solvers to converge in as few global iterations as for the analytic Neo-Hookean law, confirming robust prediction of stress fields on independent tests. 
Overall runtime is comparable to the Neo-Hookean solver and $\sim\!10^2$ faster than a Laplace-space kNN/DD baseline that lacks smoothness.%
Conclusions: CLaNN combines interpretable Laplace kinematics with ICNN-based convex potentials, yielding thermodynamically consistent and smooth constitutive responses that extrapolate across biaxial load paths and accelerate finite-element simulations of inflation tests.}
%  A Cholesky-based logarithmic parameterization of the right Cauchy--Green tensor ensures convexity and enables stable differentiation. An input convex neural network (ICNN) with nonnegative output weights defines a strictly convex stored-energy density. Second Piola--Kirchhoff stresses are obtained by differentiating the energy with respect to the stretch measure via the chain rule, which guarantees thermodynamic consistency and objective, conservative stresses. We provide explicit 2D formulas for stresses and an analytic Hessian used in Newton's method, together with a training loss that augments data misfit with anchors at the undeformed state to enforce zero energy and zero stress. The convexity of the energy yields positive-definite tangent moduli and robust convergence, while the logarithmic parameterization handles large stretches. The approach integrates efficiently with finite element solvers and recovers linear elasticity in the small-stretch limit.
\keyword{hyperelasticity; convex neural networks; continuum mechanics; finite elements}

\begin{document}

% Introduction
% \section{Introduction}
\input{parts_en/1intro}

% Kinematics
% \section{Kinematics}
\input{parts_en/2kinematics}

% Stress and consistency
% \section{Stress and Thermodynamic Consistency}
\input{parts_en/3stress}

% Architecture
% \section{CLANN architecture and its derivatives}
\input{parts_en/4architecture}

% Virtual experiment / Results
% \section{Virtual Experiment}
\input{parts_en/5results}

% Conclusions
% \section{Conclusion}
\input{parts_en/6conclusion}

% % Appendix
% \appendixtitles{yes}
% \appendixstart
% \appendix
% \input{parts_en/7appendix}

% References
\reftitle{References}
\externalbibliography{yes}
\bibliography{parts/bibliography}

\end{document}


